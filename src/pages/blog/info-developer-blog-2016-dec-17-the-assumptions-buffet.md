---
layout: ../../layouts/blog.astro
slug: 'info-developer-blog-2016-dec-17-the-assumptions-buffet'
headline: 'The Assumptions Buffet'
date: '2016-12-17'
authors: [Chris Wilk]
standfirst: '1 day, 4+ concepts, 12+ users, 10x things learnt. The assumptions buffet is great technique for product discovery'
image:
  url: 'https://media.guim.co.uk/8c8864d7fe1431a0aa84e5a0aecea0998d19ed69/0_404_4096_2458/4096.jpg'
  alt: 'Monkey Buffet Festival in Thailand'
  credit: 'Photograph: Narong Sangnak/EPA'
tags: [Advent developer blog 2016]
---

The assumptions buffet is a technique that a number of teams have used here at the Guardian as part of product discovery. The methodology is designed to challenge and test our underlying assumptions by exposing users to several different concepts in one session. It’s the equivalent of speed dating for UX researchers and users.

In one day, you can test three or four concepts with roughly a dozen users. Give it a go - we promise you will learn a surprising amount and gather the evidence needed to validate or invalidate your core assumptions quickly.

Running an assumptions buffet successfully can be tricky - good planning and practice are rewarded with more robust insights.

Preparing for your buffet
-------------------------

The assumptions buffet sounds grander than it is. The concept is actually quite simple, but unfortunately does not involve any sausage rolls.

**Before the day:**

*   Define the objective of the session. Choose your theme and what assumptions you’re planning to test
*   Prepare your concepts and if needed break these down further to raw assumptions. Create concept prototypes that articulate the assumptions clearly without any distractions
*   Create an interview script designed to elicit evidence that will confirm or invalidate each assumption. Remember not to use leading questions
*   Recruit team members to conduct user interviews and take notes
*   Recruit users that will be able to answer your questions and reflect your target audiences
*   Plan and schedule the interviews

_Example schedule:_


   <figure>
   <img alt="An assumptions buffet schedule" src="https://i.guim.co.uk/img/media/5d6fa8cd9b0848df9c26d7f231980c6cc9c7d2ea/0_0_1017_225/master/1017.jpg?width=620&quality=45&auto=format&fit=max&dpr=2&s=46bfd48cdfeea8faaae29c70ea5d5238" loading="lazy" />
   <figcaption>
     An assumptions buffet schedule
    <i>Photograph: Guardian Design Team</i>
    </figcaption>
    </figure>

**On the day:**

*   Set up a number of stations in the same room - each station will display a single concept
*   If you have the facilities, ensure that cameras and microphones are set up at each station
*   Have one person interviewing and another person taking notes at each station
*   Interview participants individually for approximately 15 minutes at each station
*   After the time is up, the user moves to the next station
*   Once each participant has been to each station, the session is over
*   Squeeze as many sessions into the day as you can

**After the buffet:**

*   Synthesise your findings and insights. The assumptions you’ve validated turn into building blocks that you can use to derive more polished designs for future product discovery work
*   Share your findings with stakeholders, teammates, and others

Conducting user interviews
--------------------------

The interviewer ideally is a trained researcher. Failing that, someone with experience in user interviews, such as product manager, can conduct the interviews instead. If the interviewer does not follow good user interview practices (by asking leading questions and such), the results and insights may be biased.

At the start, the interviewer and note-taker make the user feel comfortable by introducing themselves and their roles, the purpose of the session and why they’re conducting the interview.

The initial line of questioning is light - asking the user who they are, what they do for a living, and their association with the product.

The concept is then presented to them with a prop. This can take several forms, but commonly consist of low-fidelity paper prototypes of landing pages. The prop should be crafted for the session to expose the underlying assumptions. The interviewer spends the 15 minutes using the prop to ask a set of open questions. The note-taker is jotting down both what the user has said and any further observations about the user’s interaction with the prop.

_Example questions:_

*   “What’s your take on what \[x\] means?”
*   “Is there any kind of \[x\] you would be interested in?”
*   “How do you feel about what you’re seeing?”
*   “What would you do if you encountered this?”
*   “What does the word ‘\[x\]’ mean to you?”
*   “How do you feel about paying for \[x\]?”
*   “How would you compare \[x\] to \[y\]?”

What’s great about this technique?
----------------------------------

*   You will interrogate the core assumptions on a number of your concepts in a short period of time
*   Patterns will emerge when you aggregate the answers that your users have given. These patterns will be evidence to whether your assumptions were correct or not
*   Interviewees will go for on some tangents - these can be great nuggets of insight
*   It will inspire the team to generate more ideas or lines of inquiry
*   Most importantly, you will receive feedback on ideas without building anything

What to bear in mind?
---------------------

*   The process needs heavy staffing on the day. A standard session requires 3+ trained user interviewers, 3 good note takers, and a facilitator
*   Be sure to recruit the right participants and make sure you structure the initial interview questions to check this. Flag any participant if they seem biased
*   Don’t underestimate the preparation needed for the session. It takes a lot of time. How the concepts are presented needs to be thought through
*   The output is rich qualitative and attitudinal insight from a small number of people, and needs to be further validated during the later discovery process
*   The results are not statistically significant and should be weighted with that in mind
*   With the results, you need to be mindful of possible bias and validate insights with existing data or future live data testing.
